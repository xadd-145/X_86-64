{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "source": [
    "from spacy.lang.en import English\r\n",
    "nlp = English()"
   ],
   "outputs": [
    {
     "output_type": "stream",
     "name": "stderr",
     "text": [
      "C:\\Users\\vedan\\AppData\\Local\\Programs\\Python\\Python38\\lib\\site-packages\\numpy\\_distributor_init.py:30: UserWarning: loaded more than 1 DLL from .libs:\n",
      "C:\\Users\\vedan\\AppData\\Local\\Programs\\Python\\Python38\\lib\\site-packages\\numpy\\.libs\\libopenblas.PYQHXLVVQ7VESDPUVUADXEVJOBGHJPAY.gfortran-win_amd64.dll\n",
      "C:\\Users\\vedan\\AppData\\Local\\Programs\\Python\\Python38\\lib\\site-packages\\numpy\\.libs\\libopenblas.WCDJNK7YVMPZQ2ME2ZZHJJRJ3JIKNDB7.gfortran-win_amd64.dll\n",
      "  warnings.warn(\"loaded more than 1 DLL from .libs:\"\n"
     ]
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "source": [
    "nlp.pipe_names"
   ],
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "[]"
      ]
     },
     "metadata": {},
     "execution_count": 2
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "source": [
    "# prepare an empty model to train\r\n",
    "# nlp = spacy.load('en_web_core_sm')\r\n",
    "nlp.vocab.vectors.name = 'demo'\r\n",
    "ner = nlp.create_pipe('ner')\r\n",
    "nlp.add_pipe('ner', last=True)"
   ],
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "<spacy.pipeline.ner.EntityRecognizer at 0x2c1a6adcb20>"
      ]
     },
     "metadata": {},
     "execution_count": 3
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "source": [
    "import os\r\n",
    "import json"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "source": [
    "def load_data():\r\n",
    "    training_data = {}\r\n",
    "    for item in os.listdir(\"datasets\"):\r\n",
    "        if \".json\" in item:\r\n",
    "            temp = json.load(open(f\"./datasets/{item}\"))\r\n",
    "            if training_data == {}:\r\n",
    "                training_data = temp\r\n",
    "            else:\r\n",
    "                training_data[\"annotations\"].extend(temp[\"annotations\"])\r\n",
    "    \r\n",
    "    return training_data"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "source": [
    "json_data = load_data()"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "source": [
    "training_data = []\r\n",
    "for item in json_data[\"annotations\"]:\r\n",
    "    training_data.append({\r\n",
    "        \"text\" : item[0],\r\n",
    "        \"entities\" : item[1][\"entities\"]\r\n",
    "    })"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "source": [
    "ner = nlp.get_pipe(\"ner\")"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "source": [
    "# Add the custome NER Tags as entities into the model\r\n",
    "for label in json_data[\"classes\"]:\r\n",
    "    ner.add_label(label)"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "source": [
    "nlp.get_pipe(\"ner\").labels"
   ],
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "('BRAND', 'COMPONENT', 'CONFIG', 'PRICE', 'PRICE_TYPE', 'TYPE')"
      ]
     },
     "metadata": {},
     "execution_count": 9
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "source": [
    "from spacy.util import minibatch, compounding\r\n",
    "from pathlib import Path\r\n",
    "import random"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "source": [
    "from helper import Verbose\r\n",
    "verbose = Verbose()"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "source": [
    "epochs = 100"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "source": [
    "# Train the model\r\n",
    "optimizer = nlp.begin_training()\r\n",
    "\r\n",
    "for i in range(epochs):\r\n",
    "    verbose.make_verbose(i+1, epochs, \"training\")\r\n",
    "    for item in training_data:\r\n",
    "        if len(item[\"text\"]) > 0: # in case an empty sentence was saved while annotating\r\n",
    "            nlp.update([item], sgd=optimizer)"
   ],
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "training  [>-------------------------]  1/100 ETA: 3582 sec for 36.19 sec/steps"
     ]
    },
    {
     "output_type": "error",
     "ename": "TypeError",
     "evalue": "[E978] The Language.update method takes a list of Example objects, but got: {<class 'dict'>}",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m~\\AppData\\Local\\Temp/ipykernel_16704/692182345.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      6\u001b[0m     \u001b[1;32mfor\u001b[0m \u001b[0mitem\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mtraining_data\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      7\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mlen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mitem\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m\"text\"\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;33m>\u001b[0m \u001b[1;36m0\u001b[0m\u001b[1;33m:\u001b[0m \u001b[1;31m# in case an empty sentence was saved while annotating\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 8\u001b[1;33m             \u001b[0mnlp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mupdate\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mitem\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0msgd\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0moptimizer\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;32m~\\AppData\\Local\\Programs\\Python\\Python38\\lib\\site-packages\\spacy\\language.py\u001b[0m in \u001b[0;36mupdate\u001b[1;34m(self, examples, _, drop, sgd, losses, component_cfg, exclude)\u001b[0m\n\u001b[0;32m   1090\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mlen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mexamples\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;33m==\u001b[0m \u001b[1;36m0\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1091\u001b[0m             \u001b[1;32mreturn\u001b[0m \u001b[0mlosses\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1092\u001b[1;33m         \u001b[0mvalidate_examples\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mexamples\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m\"Language.update\"\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1093\u001b[0m         \u001b[0mexamples\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0m_copy_examples\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mexamples\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1094\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0msgd\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\AppData\\Local\\Programs\\Python\\Python38\\lib\\site-packages\\spacy\\training\\example.pyx\u001b[0m in \u001b[0;36mspacy.training.example.validate_examples\u001b[1;34m()\u001b[0m\n",
      "\u001b[1;31mTypeError\u001b[0m: [E978] The Language.update method takes a list of Example objects, but got: {<class 'dict'>}"
     ]
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "source": [
    "item"
   ],
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "{'text': 'What do you reccomend?', 'entities': []}"
      ]
     },
     "metadata": {},
     "execution_count": 22
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "source": [
    "from spacy.tokens import Doc\r\n",
    "from spacy.training import Example\r\n",
    "from nltk import word_tokenize"
   ],
   "outputs": [],
   "metadata": {}
  }
 ],
 "metadata": {
  "orig_nbformat": 4,
  "language_info": {
   "name": "python",
   "version": "3.8.7",
   "mimetype": "text/x-python",
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "pygments_lexer": "ipython3",
   "nbconvert_exporter": "python",
   "file_extension": ".py"
  },
  "kernelspec": {
   "name": "python3",
   "display_name": "Python 3.8.7 64-bit"
  },
  "interpreter": {
   "hash": "94edbaacddaafd6d45ba5506bea1ce8a371c01e0c71d6cc8e1f8803236d6de55"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}