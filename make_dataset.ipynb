{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 4,
   "source": [
    "from spacy.tokens import DocBin\r\n",
    "import spacy\r\n",
    "import json\r\n",
    "import os\r\n",
    "from tqdm import tqdm\r\n",
    "import random"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "source": [
    "def load_data():\r\n",
    "    training_data = {}\r\n",
    "    for item in os.listdir(\"datasets\"):\r\n",
    "        if \".json\" in item:\r\n",
    "            temp = json.load(open(f\"./datasets/{item}\"))\r\n",
    "            if training_data == {}:\r\n",
    "                training_data = temp\r\n",
    "            else:\r\n",
    "                training_data[\"annotations\"].extend(temp[\"annotations\"])\r\n",
    "    \r\n",
    "    return training_data"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "source": [
    "train_data = load_data()"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "source": [
    "nlp = spacy.blank(\"en\")\r\n",
    "def create_traning(TRAIN_DATA):\r\n",
    "    db = DocBin()\r\n",
    "    for text, annot in tqdm(TRAIN_DATA):\r\n",
    "        doc = nlp.make_doc(text)\r\n",
    "        ents = []\r\n",
    "        for start, end, label in annot[\"entities\"]:\r\n",
    "            span = doc.char_span(start, end, label=label, alignment_mode=\"contract\")\r\n",
    "            if span is None:\r\n",
    "                print(\"Skipping\")\r\n",
    "            else:\r\n",
    "                ents.append(span)\r\n",
    "        \r\n",
    "        doc.ents = ents\r\n",
    "        db.add(doc)\r\n",
    "    \r\n",
    "    return db"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "source": [
    "db = create_traning(train_data[\"annotations\"])"
   ],
   "outputs": [
    {
     "output_type": "stream",
     "name": "stderr",
     "text": [
      "100%|██████████| 214/214 [00:00<00:00, 1229.51it/s]"
     ]
    },
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Skipping\n",
      "Skipping\n",
      "Skipping\n",
      "Skipping\n",
      "Skipping\n",
      "Skipping\n",
      "Skipping\n",
      "Skipping\n",
      "Skipping\n",
      "Skipping\n",
      "Skipping\n",
      "Skipping\n",
      "Skipping\n",
      "Skipping\n",
      "Skipping\n",
      "Skipping\n",
      "Skipping\n",
      "Skipping\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stderr",
     "text": [
      "\n"
     ]
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "source": [
    "db.to_disk(\"./spacy_data/training.spacy\")"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [],
   "outputs": [],
   "metadata": {}
  }
 ],
 "metadata": {
  "orig_nbformat": 4,
  "language_info": {
   "name": "python",
   "version": "3.8.7",
   "mimetype": "text/x-python",
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "pygments_lexer": "ipython3",
   "nbconvert_exporter": "python",
   "file_extension": ".py"
  },
  "kernelspec": {
   "name": "python3",
   "display_name": "Python 3.8.7 64-bit"
  },
  "interpreter": {
   "hash": "94edbaacddaafd6d45ba5506bea1ce8a371c01e0c71d6cc8e1f8803236d6de55"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}